# Financial HRM Integration - Int√©gration HRM pour Trading
"""
Module d'int√©gration du vrai HRM pour l'analyse financi√®re
Adapte le mod√®le HRM aux t√¢ches de trading micro-cap
"""

import sys
import os
import torch
import numpy as np
from typing import Dict, List, Any
import logging

# Ajouter le chemin vers HRM-AI
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', 'HRM-AI'))

class FinancialHRMIntegrator:
    """
    Int√©grateur HRM pour l'analyse financi√®re
    """
    
    def __init__(self):
        self.setup_logging()
        self.logger.info("üß† Initialisation de l'int√©grateur HRM financier")
        
        # Configuration HRM
        self.hrm_config = {
            'hidden_size': 512,
            'num_heads': 8,
            'H_cycles': 2,
            'L_cycles': 2,
            'H_layers': 4,
            'L_layers': 4
        }
        
        # √âtat du mod√®le
        self.model = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.logger.info(f"üñ•Ô∏è Device: {self.device}")
        
    def setup_logging(self):
        """Configure le logging"""
        self.logger = logging.getLogger('FinancialHRMIntegrator')
    
    def load_hrm_model(self, checkpoint_path: str = None):
        """
        Charge le mod√®le HRM depuis un checkpoint
        
        Args:
            checkpoint_path: Chemin vers le checkpoint HRM
        """
        try:
            self.logger.info("üì• Chargement du mod√®le HRM...")
            
            # Si pas de checkpoint sp√©cifi√©, utiliser le checkpoint ARC-2
            if checkpoint_path is None:
                checkpoint_path = "sapientinc/HRM-checkpoint-ARC-2"
                self.logger.info(f"üîÑ Utilisation du checkpoint par d√©faut: {checkpoint_path}")
            
            # TODO: Impl√©menter le chargement du mod√®le HRM
            # from hrm import HierarchicalReasoningModel
            # self.model = HierarchicalReasoningModel.from_pretrained(checkpoint_path)
            # self.model.to(self.device)
            # self.model.eval()
            
            self.logger.info("‚úÖ Mod√®le HRM charg√© avec succ√®s")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur chargement HRM: {e}")
            return False
    
    def prepare_financial_data(self, ticker_data: Dict) -> torch.Tensor:
        """
        Pr√©pare les donn√©es financi√®res pour HRM
        
        Args:
            ticker_data: Donn√©es du ticker (prix, volume, etc.)
        
        Returns:
            Tensor format√© pour HRM
        """
        try:
            # Extraire les m√©triques financi√®res
            price = ticker_data.get('price', 0.0)
            volume = ticker_data.get('volume', 0)
            market_cap = ticker_data.get('market_cap', 0)
            
            # Normaliser les donn√©es
            normalized_data = {
                'price': price / 100.0,  # Normaliser prix
                'volume': np.log10(volume + 1) / 10.0,  # Log du volume
                'market_cap': np.log10(market_cap + 1) / 12.0,  # Log de la market cap
            }
            
            # Cr√©er un tensor 1D pour HRM
            # Format: [price, volume, market_cap, 0, 0, ...] (padding √† 512)
            data_array = np.array([
                normalized_data['price'],
                normalized_data['volume'], 
                normalized_data['market_cap']
            ])
            
            # Padding √† la taille hidden_size
            padded_data = np.zeros(self.hrm_config['hidden_size'])
            padded_data[:len(data_array)] = data_array
            
            return torch.tensor(padded_data, dtype=torch.float32).unsqueeze(0)
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur pr√©paration donn√©es: {e}")
            return None
    
    def analyze_microcap_hierarchical(self, ticker_data: Dict) -> Dict:
        """
        Analyse hi√©rarchique d'une micro-cap avec HRM
        
        Args:
            ticker_data: Donn√©es du ticker
        
        Returns:
            R√©sultat de l'analyse hi√©rarchique
        """
        try:
            if self.model is None:
                self.logger.warning("‚ö†Ô∏è Mod√®le HRM non charg√©, utilisation de l'analyse simul√©e")
                return self._simulate_hrm_analysis(ticker_data)
            
            # Pr√©parer les donn√©es
            input_tensor = self.prepare_financial_data(ticker_data)
            if input_tensor is None:
                return self._simulate_hrm_analysis(ticker_data)
            
            # TODO: Impl√©menter l'inf√©rence HRM
            # with torch.no_grad():
            #     output = self.model(input_tensor)
            #     hierarchical_analysis = self._interpret_hrm_output(output)
            
            # Pour l'instant, simulation
            hierarchical_analysis = self._simulate_hrm_analysis(ticker_data)
            
            self.logger.info(f"üß† Analyse HRM termin√©e pour {ticker_data.get('ticker', 'UNKNOWN')}")
            return hierarchical_analysis
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur analyse HRM: {e}")
            return self._simulate_hrm_analysis(ticker_data)
    
    def _simulate_hrm_analysis(self, ticker_data: Dict) -> Dict:
        """
        Simulation de l'analyse HRM (en attendant l'int√©gration compl√®te)
        """
        ticker = ticker_data.get('ticker', 'UNKNOWN')
        price = ticker_data.get('price', 0.0)
        
        # Simulation du raisonnement hi√©rarchique
        # Niveau 1: Macro (√©conomie g√©n√©rale)
        macro_score = np.random.uniform(0.3, 0.8)
        
        # Niveau 2: Secteur (industrie)
        sector_score = np.random.uniform(0.4, 0.9)
        
        # Niveau 3: Entreprise (fondamentaux)
        company_score = np.random.uniform(0.2, 0.7)
        
        # Niveau 4: Trade (d√©cision finale)
        trade_confidence = (macro_score + sector_score + company_score) / 3
        
        # D√©cision bas√©e sur la confiance
        if trade_confidence > 0.6:
            action = 'BUY'
        elif trade_confidence < 0.4:
            action = 'SELL'
        else:
            action = 'HOLD'
        
        return {
            'ticker': ticker,
            'hierarchical_analysis': {
                'macro_level': macro_score,
                'sector_level': sector_score,
                'company_level': company_score,
                'trade_level': trade_confidence
            },
            'decision': {
                'action': action,
                'confidence': trade_confidence,
                'reason': f"Analyse hi√©rarchique HRM: Macro({macro_score:.2f}), Secteur({sector_score:.2f}), Entreprise({company_score:.2f})"
            }
        }
    
    def _interpret_hrm_output(self, output: torch.Tensor) -> Dict:
        """
        Interpr√®te la sortie HRM pour l'analyse financi√®re
        """
        # TODO: Impl√©menter l'interpr√©tation de la sortie HRM
        # Cette fonction convertira la sortie du mod√®le en d√©cision de trading
        pass
    
if __name__ == "__main__":
    print("üöÄ D√©marrage de l'int√©grateur HRM financier...")
    integrator = FinancialHRMIntegrator()
    print("Module d'int√©gration HRM financier pr√™t") 